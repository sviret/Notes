\section{Introduction}

\noindent The physics reach of the HL-LHC experiments will depend critically on the ability of their trigger systems to discriminate between interesting rare events and background. For example, the CMS muon trigger will reach an unacceptably large trigger rate at high luminosity due to the number of hits in the muon detectors.  The trigger rate can be reduced to an acceptable level if tracks can be found in the inner detector and matched to the muon candidate. In order to be viable at Level 1, such a trigger decision would need to have a latency of the order of a few microseconds or less and therefore, despite the progress in computing technology expected for the next few years, given the complexity of the problem and the extremely crowded event structure, will need to be implemented mostly using specialized hardware.

\noindent Hardware-based pattern recognition for fast silicon-based triggering on charged tracks was first developed for the CDF Silicon Vertex Trigger (SVT) at the Fermilab Tevatron in the 1990's.  The method used there~\cite{bib:Rist-89} was based on a massively parallel architecture - the Associative Memory - to identify patterns efficiently at high speed, and has provided an effective solution to fast track triggers in a hadron collider environment. The Associative Memory approach was successfully used in CDF at trigger Level 2 and the same approach is now being implemented for Atlas (FTK), also at Level 2, albeit with a much improved hardware architecture implemented with modern technology.  Since the Associative Memory approach is so far the only proven approach to silicon based tracking triggers in a hadron collider environment, it is chosen here as the baseline in our R\&D program for CMS. However, due to the much higher occupancy and event rates at the HL-LHC, there are many challenges to perform pattern recognition and track fitting at Level 1 with the requirement of a much shorter latency. Therefore, it is crucial for CMS to demonstrate, over the next few years, the technical feasibility of a tracking trigger at Level 1. 

\noindent Typical track reconstruction in a tracking detector consists of two steps: pattern recognition followed by track fitting. Pattern recognition involves choosing, from all the hits present in the detector, those hits that were potentially caused by the same particle. This stage produces a set of "hits of interest". Track fitting involves extracting track parameters from the coordinates of the "hits of interest". For cases for which time constraint is not so stringent, track reconstruction has been implemented using software computational techniques to identify patterns and perform track fitting, often using processors running in the upper levels of a data acquisition system to perform the task.  However, such algorithms are usually time-consuming because the pattern recognition and track fitting steps are necessarily executed many times to find and fit all the tracks for each event.  Software algorithms running on standard CPU's are typically not fast enough for these extreme applications. As will be described below, in the traditional Associative Memory approach, the pattern recognition stage is performed by Associative Memories, while track fitting is done using a simplified least squares fitting algorithm using a linear expansion of the analytical expression of the track trajectories around the hit locations in the detector. All this is implemented on a massively parallel data processing architecture.

\noindent A block diagram of the Associative Memory architecture is shown in Figure 1.  This device solves the combinatorial problem, inherent to this kind of pattern recognition algorithms, by employing a massively parallel architecture to compare each detector hit to a large number of pre-calculated geometrical patterns simultaneously. Then, the selected patterns are processed using fast FPGAs to perform track fitting. Since each pattern corresponds to a very narrow "road" through the detector, the usual helical fit is much simplified and fast by using a pre-calculated set of parameter values for the center of the road and applying corrections that are a linear function of the actual hit positions in each layer. 

\noindent The SVT approach was very successful and CDF was the first hadron collider experiment in HEP to incorporate a fast secondary vertex track trigger~\cite{bib:Ade-06}, \cite{bib:Ade-07} to find all tracks produced in each collision and precisely measure their properties within about 30 microseconds from the time of the collision. The SVT significantly extended the physics reach of CDF opening the way to measurements that would have been impossible otherwise.

\paragraph{\bf The Challenges for tracking trigger at L1\\}

\noindent Level-1 triggering at the HL-LHC will be extremely challenging because the input data rate into the tracking trigger system will be at ~50-100 Tbps level, and the total Level 1 trigger latency allowed is only about 10 micro-seconds. Current estimates show that only a few microseconds are available for track finding and fitting.  

\noindent Two difficult challenges one has to face are data formatting and the Associative Memory. Data Formatting is where stubs from many thousands of silicon modules must be organized into eta-phi trigger towers. Due to finite size of the beam's luminous region in z and the finite curvature of charged particles in the magnetic field some stubs need to be sent to multiple geometrical towers in an intelligent way. This is especially challenging for Level 1 track trigger since the stubs coming from each trigger tower must be organized, possibly duplicated and finally delivered to the appropriate Associative Memory chips within a very short time (of the order of micro-second). Communication between processing elements in different towers requires very high bandwidth and very low latency. Approximately three orders of magnitude more Associative Memory patterns are required compared to what was used in the original CDF SVT. We can use the Atlas FastTracK (FTK)~\cite{bib:FTK-10} project as an example. Since the design requirements of the FTK system are now known from extensive simulations, numbers from FTK, in some case, can be used as an order of magnitude estimate for CMS. The original CDF SVT system, in operation from 2001 to 2005, had a total of 384,000 Associative Memory patterns, while the ATLAS FTK system for the Level 2 trigger requires effectively ~ 1 billion patterns in order to handle a luminosity of $3\times10^{34}~cm^{-2}s^{-1}$~\cite{bib:FTK-10}. This is three orders of magnitude more Associative Memory patterns than the SVT. The Level 1 Track Trigger upgrade for CMS has the advantage of having the Pt stub finding stage done upstream already, therefore it may not require as many patterns as that for FTK. However, more patterns would make the second track fitting stage easier and faster. More importantly, the pattern recognition engine has to run at much higher speed for L1 track trigger. In addition to the challenges above, extremely fast and effective track fitting is also required. Extensive R\&D and experimentation of innovative ideas is needed in this area.

\paragraph{\bf On going R\&D activities at CMS\\}

\noindent Motivated by the challenges described above, over the past few years, a number of institutions in CMS have been working on R\&D projects related to the development of fast tracking based on the Associative Memory approach. INFN has been working together with the Atlas FTK team exploring the possibility of using FTK associative memory chips for CMS applications. Lyon group has been focusing on the development of the necessary simulation tools for the Associative Memory approach for the CMS case, and on the possibility of using a new algorithm, based on Hough's transforms, to replace the conventional SVT-style, linearized track fitting algorithm. 

\noindent Fermilab carried on a focused R\&D program to develop hardware-based technology to advance the state-of-the-art of pattern recognition and track reconstruction for fast triggering. Specifically, Fermilab has been developing a new Data Formatting system based on full-mesh ATCA and exploring new Associative Memory VLSI structures based on new technologies both 2-dimensional and 3-dimensional. The 3D approach to Associative Memory implementation is particularly appealing because adding the "third" dimension opens up the possibility for new architectures that would dramatically increase the achievable density of patterns and the pattern recognition power. 

\noindent The long-term goal of this R\&D efforts is to develop all necessary critical technologies to the point where we can ultimately propose them as a viable solution to the CMS L1 tracking trigger problem for HL-LHC. Major progresses have been made recently. INFN has done the initial measurement of AMchip03 latency, Lyon's group had already initial success with the simulation of the Associative Memory and has performed some detailed studies on an algorithm based on Hough's transform. Fermilab has successfully tested the first Data Formatting system components (ATCA motherboard nicknamed Pulsar-IIa, RTM and mezzanine cards) and they all work well, actually better than expected. Fermilab is now ready to test the first Associative Memory 2D prototype chips expected to be delivered at the end of November 2013. Given the progress made by this R\&D program in the last few years, we believe it is now time to move to the next important step and build a Vertical Slice Demonstration System using high luminosity simulated data to implement and study a "vertical slice" of the full tracking trigger path, measure trigger latency and efficiency, study the overall performance, identify possible bottlenecks and issues and, hopefully, find appropriate solutions.  It turns out that the Pulsar II hardware design is flexible enough to be used as the main workhorse to build the Vertical Slice Demonstration System.

\noindent The architecture we have recently proposed for the CMS L1 tracking trigger system is based on ATCA with full-mesh backplane. The large inter-board communication bandwidth provided by the full-mesh backplane is used to time multiplex the high volume (~ 50 Tbps) of incoming data in such a way that the I/O bandwidth demands are manageable at the board and chip level, making it possible for an early technical demonstration with existing technology. The resulting architecture is scalable, flexible and open. For example, it allows different pattern recognition architectures and algorithms to be explored and compared within the same platform. Also, given that AMC specifications are designed to work with both ATCA and MicroTCA, this architecture allows a natural long term integration of TK-DAQ (AMC card based) and TK-TRIG (ATCA based).

\noindent The proposed architecture and system demonstration concept has been well received within the tracker Phase 2 upgrade community and we are now working on the details to better define the concept.  At the same time, we are developing collaborations with international partners within CMS. One of the main activities in the coming year (FY14) will consist of extensive simulation efforts, by physicists, to establish technical specifications based on Phase 2 physics goals. At the same time, students and postdocs from all groups will be offered a unique opportunity to develop hardware experience by getting involved with the design, construction and commissioning of the vertical slice demonstration over the next few years. Some of the groups, for the longer term, are also interested in getting involved with the development of the algorithms for the post-track-finding stages and of the interfaces with the global trigger. 

\noindent In this document we will describe a track trigger architecture and system demonstration as a proposal for Phase 2 tracking trigger R\&D for CMS. This will be a living document, serving multiple purposes. It is intended to define the tracking trigger project and organize the efforts towards the Technical Proposal, the Vertical Slice Demonstration System, and the TDR (Technical Design Report). It will be written in such a way to make it easy not only for new groups to learn, but also to communicate with all the relevant tracker, trigger and physics groups.

\clearpage
